{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart sound classification Keras\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\apt\\Anaconda3\\envs\\ml\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import specgram\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from numpy import array\n",
    "from numpy import argmax \n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting features from audio files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parse audio funtion takes all the files divided into subfolders with their class label names and extract features does extract meaningful features from each audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(file_name):\n",
    "    X, sample_rate = librosa.load(file_name)\n",
    "    stft = np.abs(librosa.stft(X))\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "    return mfccs,chroma,mel,contrast,tonnetz\n",
    "\n",
    "def parse_audio_files(parent_dir,sub_dirs,file_ext='*.wav'):\n",
    "    features, labels = np.empty((0,193)), np.empty(0)\n",
    "    for label, sub_dir in enumerate(sub_dirs):\n",
    "        for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
    "            mfccs, chroma, mel, contrast,tonnetz = extract_feature(fn)\n",
    "            #Stack arrays in sequence horizontally (column wise).\n",
    "            #a = np.array((1,2,3)) b = np.array((2,3,4))\n",
    "            #np.hstack((a,b))  array([1, 2, 3, 2, 3, 4])\n",
    "            ext_features = np.hstack([mfccs,chroma,mel,contrast,tonnetz])\n",
    "            #Stack arrays in sequence vertically (row wise). So each audio files features are saved in new rows\n",
    "            features = np.vstack([features,ext_features]) \n",
    "            print(fn.split('/')[4].split(\"\\\\\")[1])\n",
    "            labels = np.append(labels, fn.split('/')[4].split(\"\\\\\")[1])\n",
    "            #labels = np.append(labels, fn.split('/')[6].split('-')[2][0])\n",
    "    return np.array(features), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = 'C:/Users/apt/Desktop/physionet'\n",
    "sub_dirs = ['testmur','testnorm']\n",
    "features, labels = parse_audio_files(parent_dir,sub_dirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Saved the features in NP array so as reuse and avoid repeated time consuming feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.save(\"TestRecordedNormalJhonMurmurFeatures\" + '.npy', features)\n",
    "np.save(\"TestRecordedNormalJhonMurmurLabels\" + '.npy', labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================The extracted features================\n",
      "[[-3.86631022e+02  1.78301213e+02  6.85775411e+01 ...  1.33809307e-02\n",
      "   3.61587288e-03  1.16107564e-02]\n",
      " [-3.92341076e+02  1.79758613e+02  6.16161795e+01 ...  2.73219725e-02\n",
      "   1.05619922e-03  1.78745035e-02]\n",
      " [-4.01152468e+02  1.69678650e+02  6.85314371e+01 ...  1.21206933e-02\n",
      "   4.79127069e-03  1.23095707e-02]\n",
      " ...\n",
      " [-4.53560591e+02  1.50814845e+02  1.05998614e+02 ...  3.75065411e-02\n",
      "   1.16891035e-02  1.23915670e-02]\n",
      " [-4.46932479e+02  1.71429773e+02  1.17186192e+02 ...  1.11238218e-02\n",
      "   4.40638816e-03  4.38996250e-03]\n",
      " [-4.72077197e+02  1.46631426e+02  1.06092229e+02 ...  2.86870771e-02\n",
      "   7.12759197e-03  1.56826852e-02]]\n",
      "==============================================================\n",
      "=====The labels of classification in categorical variable======\n",
      "['normal' 'normal' 'normal' ... 'abnormal' 'abnormal' 'abnormal']\n",
      "===================Labels converted to binary ==============================\n",
      "[1 1 1 ... 0 0 0]\n",
      "=====Then to one hot encoding as ML algorithms cannot work with categorical data directly=====\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "[ True  True False ...  True  True  True]\n",
      "===================Input shape ==============================\n",
      "(1825, 193)\n",
      "(1825, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features = np.load(\"Trainingpsypeter2Features\"+ '.npy')\n",
    "labels = np.load(\"Trainingpsypeter2Labels\" + '.npy')\n",
    "\n",
    "Testfeatures = np.load(\"TestRecordedNormalJhonMurmurFeatures\"+ '.npy')\n",
    "testLabels = np.load(\"TestRecordedNormalJhonMurmurLabels\" + '.npy')\n",
    "\n",
    "print(\"========================The extracted features================\")\n",
    "\n",
    "print(features)\n",
    "print(\"==============================================================\")\n",
    "print(\"=====The labels of classification in categorical variable======\")\n",
    "print(labels)\n",
    "print(\"===================Labels converted to binary ==============================\")\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(labels)\n",
    "print(integer_encoded)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "labels = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "print(\"=====Then to one hot encoding as ML algorithms cannot work with categorical data directly=====\")\n",
    "\n",
    "print(labels)\n",
    "# invert first example\n",
    "#inverted = label_encoder.inverse_transform([argmax(onehot_encoded[::-1])])\n",
    "#print(inverted)\n",
    "#labels = tf.keras.utils.to_categorical(labels, 3)\n",
    "#train_test_split = np.random.rand(len(features)) < 0.70\n",
    "train_x = features[train_test_split]\n",
    "train_y = labels[train_test_split]\n",
    "print(train_test_split)\n",
    "test_x = features[~train_test_split]\n",
    "test_y = labels[~train_test_split]\n",
    "print(\"===================Input shape ==============================\")\n",
    "#features = np.asarray(features).reshape(len(features),193,1)\n",
    "#labels = np.asarray(labels).reshape(len(labels),2,1)\n",
    "print(features.shape)\n",
    "print(labels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow approch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially have built Artificial Neural network thorugh Tensor flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1825, 193)\n",
      "193\n"
     ]
    }
   ],
   "source": [
    "training_epochs = 2000\n",
    "n_dim = features.shape[1]\n",
    "print(features.shape)\n",
    "print(features.shape[1])\n",
    "n_classes = 2\n",
    "n_hidden_units_one = 300 \n",
    "n_hidden_units_two = 400\n",
    "n_hidden_units_three = 350\n",
    "sd = 1 / np.sqrt(n_dim)\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32,[None,n_dim])\n",
    "Y = tf.placeholder(tf.float32,[None,n_classes])\n",
    "\n",
    "\n",
    "W_1 = tf.Variable(tf.random_normal([n_dim,n_hidden_units_one], mean = 0, stddev=sd))\n",
    "b_1 = tf.Variable(tf.random_normal([n_hidden_units_one], mean = 0, stddev=sd))\n",
    "h_1 = tf.nn.relu(tf.matmul(X,W_1) + b_1)\n",
    "\n",
    "\n",
    "W_2 = tf.Variable(tf.random_normal([n_hidden_units_one,n_hidden_units_two], mean = 0, stddev=sd))\n",
    "b_2 = tf.Variable(tf.random_normal([n_hidden_units_two], mean = 0, stddev=sd))\n",
    "h_2 = tf.nn.tanh(tf.matmul(h_1,W_2) + b_2)\n",
    "\n",
    "\n",
    "W_3 = tf.Variable(tf.random_normal([n_hidden_units_two, n_hidden_units_three], mean = 0, stddev=sd))\n",
    "b_3 = tf.Variable(tf.random_normal([n_hidden_units_three], mean = 0, stddev=sd))\n",
    "h_3 = tf.nn.sigmoid(tf.matmul(h_2,W_3) + b_3)\n",
    "\n",
    "\n",
    "W = tf.Variable(tf.random_normal([n_hidden_units_three,n_classes], mean = 0, stddev=sd))\n",
    "b = tf.Variable(tf.random_normal([n_classes], mean = 0, stddev=sd))\n",
    "y_ = tf.nn.softmax(tf.matmul(h_3,W) + b)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost_function = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(y_), reduction_indices=[1])) \n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "cost_history = np.empty(shape=[1],dtype=float)\n",
    "y_true, y_pred = None, None\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(training_epochs):            \n",
    "        _,cost = sess.run([optimizer,cost_function],feed_dict={X:train_x,Y:train_y})\n",
    "        cost_history = np.append(cost_history,cost)\n",
    "    \n",
    "    y_pred = sess.run(tf.argmax(y_,1),feed_dict={X: test_x})\n",
    "    y_true = sess.run(tf.argmax(test_y,1))\n",
    "    save_path = saver.save(sess, \"C:/Users/apt/Desktop/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "  # Restore variables from disk.\n",
    "  saver.restore(sess, \"C:/Users/apt/Desktop/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Score: 0.777\n",
      "F-Score: 0.777\n",
      "F-Score: 0.777\n",
      "F-Score: None\n"
     ]
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.plot(cost_history)\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.axis([0,training_epochs,0,np.max(cost_history)])\n",
    "plt.show()\n",
    "\n",
    "p,r,f,s = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "print(\"F-Score:\", round(f,3))\n",
    "print(\"F-Score:\", round(p,3))\n",
    "print(\"F-Score:\", round(r,3))\n",
    "print(\"F-Score:\", s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras over tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 193 Classes: 2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def assure_path_exists(path):\n",
    "    mydir = os.path.join(os.getcwd(), path)\n",
    "    if not os.path.exists(mydir):\n",
    "        os.makedirs(mydir)\n",
    "\n",
    "# neural network dimensions\n",
    "n_dim = train_x.shape[1]\n",
    "n_classes = train_y.shape[1]\n",
    "n_hidden_units_1 = n_dim\n",
    "n_hidden_units_2 = 400 # approx n_dim * 2\n",
    "n_hidden_units_3 = 600\n",
    "n_hidden_units_4 = 400 #\n",
    "n_hidden_units_5 = 200 # half of layer 2\n",
    "\n",
    "checkpoint_dir = \"model\"\n",
    "assure_path_exists(checkpoint_dir)\n",
    "\n",
    "print (\"Features:\", n_dim, \"Classes:\", n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\apt\\Anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(193, input_dim=193, activation=\"relu\", kernel_initializer=\"normal\")`\n",
      "  import sys\n",
      "C:\\Users\\apt\\Anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(400, activation=\"sigmoid\", kernel_initializer=\"normal\")`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\apt\\Anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(600, activation=\"tanh\", kernel_initializer=\"normal\")`\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\apt\\Anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(400, activation=\"relu\", kernel_initializer=\"normal\")`\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\apt\\Anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(2, activation=\"softmax\", kernel_initializer=\"normal\")`\n",
      "C:\\Users\\apt\\Anaconda3\\envs\\ml\\lib\\site-packages\\keras\\models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1269 samples, validate on 556 samples\n",
      "Epoch 1/100\n",
      "1269/1269 [==============================] - 3s 2ms/step - loss: 0.8836 - acc: 0.5248 - val_loss: 0.7690 - val_acc: 0.5701\n",
      "Epoch 2/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.7696 - acc: 0.5406 - val_loss: 0.6882 - val_acc: 0.5701\n",
      "Epoch 3/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.7442 - acc: 0.5382 - val_loss: 0.6756 - val_acc: 0.5701\n",
      "Epoch 4/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.7375 - acc: 0.5288 - val_loss: 0.7327 - val_acc: 0.4299\n",
      "Epoch 5/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.7097 - acc: 0.5705 - val_loss: 0.6925 - val_acc: 0.5701\n",
      "Epoch 6/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.7204 - acc: 0.5461 - val_loss: 0.6838 - val_acc: 0.5701\n",
      "Epoch 7/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.7108 - acc: 0.5674 - val_loss: 0.7368 - val_acc: 0.4299\n",
      "Epoch 8/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.7048 - acc: 0.5603 - val_loss: 0.6785 - val_acc: 0.6079\n",
      "Epoch 9/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.7073 - acc: 0.5540 - val_loss: 0.6878 - val_acc: 0.5486\n",
      "Epoch 10/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.7013 - acc: 0.5579 - val_loss: 0.7092 - val_acc: 0.4299\n",
      "Epoch 11/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.7063 - acc: 0.5461 - val_loss: 0.6737 - val_acc: 0.5701\n",
      "Epoch 12/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.7028 - acc: 0.5587 - val_loss: 0.6701 - val_acc: 0.5701\n",
      "Epoch 13/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.6901 - acc: 0.5831 - val_loss: 0.6397 - val_acc: 0.6439\n",
      "Epoch 14/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.7005 - acc: 0.5918 - val_loss: 0.7166 - val_acc: 0.5701\n",
      "Epoch 15/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.6937 - acc: 0.6052 - val_loss: 0.6288 - val_acc: 0.6835\n",
      "Epoch 16/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.7026 - acc: 0.5997 - val_loss: 0.6366 - val_acc: 0.6745\n",
      "Epoch 17/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.6737 - acc: 0.6336 - val_loss: 0.6302 - val_acc: 0.6745\n",
      "Epoch 18/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.6594 - acc: 0.6351 - val_loss: 0.6177 - val_acc: 0.6853\n",
      "Epoch 19/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.6500 - acc: 0.6643 - val_loss: 0.5740 - val_acc: 0.7212\n",
      "Epoch 20/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.6712 - acc: 0.6501 - val_loss: 0.5840 - val_acc: 0.7212\n",
      "Epoch 21/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.6459 - acc: 0.6635 - val_loss: 0.6020 - val_acc: 0.7104\n",
      "Epoch 22/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.6437 - acc: 0.6848 - val_loss: 0.6701 - val_acc: 0.6709\n",
      "Epoch 23/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.6460 - acc: 0.6872 - val_loss: 0.5974 - val_acc: 0.6888\n",
      "Epoch 24/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.6312 - acc: 0.6974 - val_loss: 0.5757 - val_acc: 0.7356\n",
      "Epoch 25/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.6352 - acc: 0.6832 - val_loss: 0.5517 - val_acc: 0.7518\n",
      "Epoch 26/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.6185 - acc: 0.6887 - val_loss: 0.5557 - val_acc: 0.7518\n",
      "Epoch 27/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.6140 - acc: 0.7029 - val_loss: 0.5366 - val_acc: 0.7446\n",
      "Epoch 28/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.6358 - acc: 0.7124 - val_loss: 0.6925 - val_acc: 0.5809\n",
      "Epoch 29/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.6403 - acc: 0.6856 - val_loss: 0.6014 - val_acc: 0.7392\n",
      "Epoch 30/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.6241 - acc: 0.6935 - val_loss: 0.5901 - val_acc: 0.7338\n",
      "Epoch 31/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.6236 - acc: 0.7076 - val_loss: 0.5551 - val_acc: 0.7500\n",
      "Epoch 32/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.6136 - acc: 0.7155 - val_loss: 0.6134 - val_acc: 0.7590\n",
      "Epoch 33/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.6210 - acc: 0.7210 - val_loss: 0.5378 - val_acc: 0.7644\n",
      "Epoch 34/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.6106 - acc: 0.7242 - val_loss: 0.5401 - val_acc: 0.7644\n",
      "Epoch 35/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.6319 - acc: 0.7076 - val_loss: 0.5674 - val_acc: 0.7572\n",
      "Epoch 36/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.5955 - acc: 0.7407 - val_loss: 0.5233 - val_acc: 0.7500\n",
      "Epoch 37/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.6102 - acc: 0.7116 - val_loss: 0.5245 - val_acc: 0.7698\n",
      "Epoch 38/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.6274 - acc: 0.7163 - val_loss: 0.5274 - val_acc: 0.7590\n",
      "Epoch 39/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.5973 - acc: 0.7218 - val_loss: 0.5273 - val_acc: 0.7608\n",
      "Epoch 40/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.6244 - acc: 0.6990 - val_loss: 0.6565 - val_acc: 0.6331\n",
      "Epoch 41/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.6081 - acc: 0.7297 - val_loss: 0.5751 - val_acc: 0.7032\n",
      "Epoch 42/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.6265 - acc: 0.7100 - val_loss: 0.5960 - val_acc: 0.6835\n",
      "Epoch 43/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.5973 - acc: 0.7155 - val_loss: 0.5248 - val_acc: 0.7662\n",
      "Epoch 44/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.5978 - acc: 0.7218 - val_loss: 0.5429 - val_acc: 0.7518\n",
      "Epoch 45/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.5995 - acc: 0.7329 - val_loss: 0.5814 - val_acc: 0.6996\n",
      "Epoch 46/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.6020 - acc: 0.7273 - val_loss: 0.5426 - val_acc: 0.7554\n",
      "Epoch 47/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.5958 - acc: 0.7360 - val_loss: 0.5371 - val_acc: 0.7752\n",
      "Epoch 48/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.5901 - acc: 0.7376 - val_loss: 0.6073 - val_acc: 0.7050\n",
      "Epoch 49/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.5959 - acc: 0.7273 - val_loss: 0.5284 - val_acc: 0.7482\n",
      "Epoch 50/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.5935 - acc: 0.7266 - val_loss: 0.5774 - val_acc: 0.7680\n",
      "Epoch 51/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.6144 - acc: 0.7179 - val_loss: 0.5389 - val_acc: 0.7482\n",
      "Epoch 52/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.6123 - acc: 0.7195 - val_loss: 0.5125 - val_acc: 0.7716\n",
      "Epoch 53/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.6126 - acc: 0.7400 - val_loss: 0.5598 - val_acc: 0.7446\n",
      "Epoch 54/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.5826 - acc: 0.7313 - val_loss: 0.5354 - val_acc: 0.7662\n",
      "Epoch 55/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.6296 - acc: 0.6919 - val_loss: 0.5576 - val_acc: 0.7662\n",
      "Epoch 56/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.6139 - acc: 0.7006 - val_loss: 0.5562 - val_acc: 0.7446\n",
      "Epoch 57/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.6053 - acc: 0.7203 - val_loss: 0.6641 - val_acc: 0.7644\n",
      "Epoch 58/100\n",
      "1269/1269 [==============================] - 2s 1ms/step - loss: 0.6054 - acc: 0.7281 - val_loss: 0.7458 - val_acc: 0.5701\n",
      "Epoch 59/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.6301 - acc: 0.7116 - val_loss: 0.5354 - val_acc: 0.7572\n",
      "Epoch 60/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.6059 - acc: 0.7242 - val_loss: 0.5460 - val_acc: 0.7752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.6035 - acc: 0.7297 - val_loss: 0.5407 - val_acc: 0.7662\n",
      "Epoch 62/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.5932 - acc: 0.7526 - val_loss: 0.5228 - val_acc: 0.7770\n",
      "Epoch 63/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.5879 - acc: 0.7392 - val_loss: 0.5304 - val_acc: 0.7446\n",
      "Epoch 64/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.5838 - acc: 0.7455 - val_loss: 0.6267 - val_acc: 0.7230\n",
      "Epoch 65/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.5934 - acc: 0.7352 - val_loss: 0.5150 - val_acc: 0.7752\n",
      "Epoch 66/100\n",
      "1269/1269 [==============================] - 2s 1ms/step - loss: 0.5912 - acc: 0.7329 - val_loss: 0.5733 - val_acc: 0.7752\n",
      "Epoch 67/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.5972 - acc: 0.7510 - val_loss: 0.5725 - val_acc: 0.7266\n",
      "Epoch 68/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.5762 - acc: 0.7321 - val_loss: 0.5703 - val_acc: 0.7698\n",
      "Epoch 69/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.5772 - acc: 0.7478 - val_loss: 0.5218 - val_acc: 0.7842\n",
      "Epoch 70/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.5729 - acc: 0.7368 - val_loss: 0.5113 - val_acc: 0.7698\n",
      "Epoch 71/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.5817 - acc: 0.7321 - val_loss: 0.5214 - val_acc: 0.7608\n",
      "Epoch 72/100\n",
      "1269/1269 [==============================] - 2s 1ms/step - loss: 0.5779 - acc: 0.7581 - val_loss: 0.5033 - val_acc: 0.7770\n",
      "Epoch 73/100\n",
      "1269/1269 [==============================] - 2s 1ms/step - loss: 0.6126 - acc: 0.7289 - val_loss: 0.5367 - val_acc: 0.7752\n",
      "Epoch 74/100\n",
      "1269/1269 [==============================] - 2s 1ms/step - loss: 0.5604 - acc: 0.7549 - val_loss: 0.5602 - val_acc: 0.7266\n",
      "Epoch 75/100\n",
      "1269/1269 [==============================] - 2s 1ms/step - loss: 0.5759 - acc: 0.7455 - val_loss: 0.5380 - val_acc: 0.7770\n",
      "Epoch 76/100\n",
      "1269/1269 [==============================] - 2s 1ms/step - loss: 0.5720 - acc: 0.7463 - val_loss: 0.5269 - val_acc: 0.7896\n",
      "Epoch 77/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.5820 - acc: 0.7494 - val_loss: 0.4831 - val_acc: 0.7842\n",
      "Epoch 78/100\n",
      "1269/1269 [==============================] - 2s 1ms/step - loss: 0.5695 - acc: 0.7549 - val_loss: 0.5092 - val_acc: 0.7644\n",
      "Epoch 79/100\n",
      "1269/1269 [==============================] - 2s 1ms/step - loss: 0.5702 - acc: 0.7597 - val_loss: 0.5122 - val_acc: 0.7698\n",
      "Epoch 80/100\n",
      "1269/1269 [==============================] - 2s 1ms/step - loss: 0.5550 - acc: 0.7612 - val_loss: 0.5412 - val_acc: 0.7230\n",
      "Epoch 81/100\n",
      "1269/1269 [==============================] - 2s 1ms/step - loss: 0.5873 - acc: 0.7439 - val_loss: 0.4936 - val_acc: 0.7770\n",
      "Epoch 82/100\n",
      "1269/1269 [==============================] - 2s 1ms/step - loss: 0.5614 - acc: 0.7636 - val_loss: 0.5618 - val_acc: 0.7590\n",
      "Epoch 83/100\n",
      "1269/1269 [==============================] - 2s 1ms/step - loss: 0.5804 - acc: 0.7541 - val_loss: 0.5057 - val_acc: 0.7752\n",
      "Epoch 84/100\n",
      "1269/1269 [==============================] - 2s 1ms/step - loss: 0.5666 - acc: 0.7533 - val_loss: 0.5516 - val_acc: 0.6817\n",
      "Epoch 85/100\n",
      "1269/1269 [==============================] - 2s 1ms/step - loss: 0.5586 - acc: 0.7589 - val_loss: 0.4812 - val_acc: 0.7896\n",
      "Epoch 86/100\n",
      "1269/1269 [==============================] - 2s 1ms/step - loss: 0.5842 - acc: 0.7628 - val_loss: 0.4963 - val_acc: 0.7626\n",
      "Epoch 87/100\n",
      "1269/1269 [==============================] - 2s 1ms/step - loss: 0.5705 - acc: 0.7652 - val_loss: 0.5434 - val_acc: 0.7896\n",
      "Epoch 88/100\n",
      "1269/1269 [==============================] - 2s 1ms/step - loss: 0.5692 - acc: 0.7518 - val_loss: 0.4950 - val_acc: 0.7752\n",
      "Epoch 89/100\n",
      "1269/1269 [==============================] - 2s 1ms/step - loss: 0.5586 - acc: 0.7691 - val_loss: 0.5038 - val_acc: 0.7716\n",
      "Epoch 90/100\n",
      "1269/1269 [==============================] - 2s 1ms/step - loss: 0.5682 - acc: 0.7494 - val_loss: 0.5244 - val_acc: 0.7266\n",
      "Epoch 91/100\n",
      "1269/1269 [==============================] - 2s 1ms/step - loss: 0.5739 - acc: 0.7486 - val_loss: 0.4965 - val_acc: 0.7914\n",
      "Epoch 92/100\n",
      "1269/1269 [==============================] - 2s 1ms/step - loss: 0.5790 - acc: 0.7675 - val_loss: 0.4803 - val_acc: 0.7860\n",
      "Epoch 93/100\n",
      "1269/1269 [==============================] - 2s 1ms/step - loss: 0.5672 - acc: 0.7557 - val_loss: 0.5241 - val_acc: 0.7986\n",
      "Epoch 94/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.5662 - acc: 0.7675 - val_loss: 0.5326 - val_acc: 0.7392\n",
      "Epoch 95/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.5585 - acc: 0.7589 - val_loss: 0.5328 - val_acc: 0.7608\n",
      "Epoch 96/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.5623 - acc: 0.7533 - val_loss: 0.4894 - val_acc: 0.8004\n",
      "Epoch 97/100\n",
      "1269/1269 [==============================] - 2s 1ms/step - loss: 0.5496 - acc: 0.7754 - val_loss: 0.4997 - val_acc: 0.7986\n",
      "Epoch 98/100\n",
      "1269/1269 [==============================] - 2s 1ms/step - loss: 0.5717 - acc: 0.7683 - val_loss: 0.4975 - val_acc: 0.7698\n",
      "Epoch 99/100\n",
      "1269/1269 [==============================] - 2s 2ms/step - loss: 0.5612 - acc: 0.7738 - val_loss: 0.5077 - val_acc: 0.7896\n",
      "Epoch 100/100\n",
      "1269/1269 [==============================] - 4s 4ms/step - loss: 0.5749 - acc: 0.7778 - val_loss: 0.4773 - val_acc: 0.796868 - acc\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "def create_model(activation_function='relu', init_type='normal', optimiser='RMSprop', dropout_rate=0.5):\n",
    "    model = Sequential()\n",
    "    # layer 1\n",
    "    model.add(Dense(n_hidden_units_1, input_dim=n_dim, init=init_type, activation='relu'))\n",
    "    # layer 2\n",
    "    model.add(Dense(n_hidden_units_2, init=init_type, activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    # layer 3\n",
    "    model.add(Dense(n_hidden_units_3, init=init_type, activation='tanh'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "     # layer 4\n",
    "    model.add(Dense(n_hidden_units_4, init=init_type, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    #model.add(Dense(n_hidden_units_4, init=init_type, activation='relu'))\n",
    "    #model.add(Dropout(dropout_rate))\n",
    "    \n",
    " \n",
    "    \n",
    "    # output layer\n",
    "    model.add(Dense(n_classes, init=init_type, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimiser, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# a stopping function to stop training before we excessively overfit to the training set\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=20, verbose=1, mode='auto')\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "history = model.fit(train_x, train_y,  nb_epoch=100, batch_size=10, validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Score: 0.788\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics \n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "# obtain the prediction probabilities\n",
    "y_prob = model.predict_proba(test_x, verbose=0)\n",
    "#y_pred = np_utils.probas_to_classes(y_prob)\n",
    "#replaced above probas_to_classes as updated keras doesnt have it  \n",
    "y_pred = y_prob.argmax(axis=-1)\n",
    "y_true = np.argmax(test_y, 1)\n",
    "\n",
    "#roc = metrics.roc_auc_score(test_y, y_prob)\n",
    "#print (\"ROC:\",  round(roc,2))\n",
    "\n",
    "# evaluate the model\n",
    "#score, accuracy = model.evaluate(test_x, test_y, batch_size=32)\n",
    "#print(\"\\nAccuracy = {:.2f}\".format(accuracy))\n",
    "\n",
    "p,r,f,s = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "print (\"F-Score:\", round(f,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refinement and Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of a deep neural network is highly dependent on many configurable hyper-parameters, values that govern how the model actually works, and which are not changed during the course of learning. Some of these parameters will have a greater influence than others. The classic machine learning solution to this challenge is GridSearch, to successively train separate instances of a model with distinct values of key parameters, and then compare the resulting accuracy scores to identify which combination of parameters has produced the best results.\n",
    "\n",
    "Have started searching for best parameters using this startegy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\apt\\Anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(193, input_dim=193, activation=\"relu\", kernel_initializer=\"normal\")`\n",
      "  import sys\n",
      "C:\\Users\\apt\\Anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(400, activation=\"relu\", kernel_initializer=\"normal\")`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\apt\\Anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(200, activation=\"relu\", kernel_initializer=\"normal\")`\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\apt\\Anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(2, activation=\"softmax\", kernel_initializer=\"normal\")`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearch...\n",
      "GridSearch complete\n",
      "Best: 0.451208 using {'dropout_rate': 0.0}\n",
      "0.451208 (0.414039) with: {'dropout_rate': 0.0}\n",
      "0.215459 (0.304705) with: {'dropout_rate': 0.1}\n",
      "0.220290 (0.301347) with: {'dropout_rate': 0.2}\n",
      "0.240580 (0.170218) with: {'dropout_rate': 0.3}\n",
      "0.119807 (0.165350) with: {'dropout_rate': 0.4}\n",
      "0.248309 (0.176476) with: {'dropout_rate': 0.5}\n",
      "0.131401 (0.185829) with: {'dropout_rate': 0.6}\n",
      "0.161353 (0.228187) with: {'dropout_rate': 0.7}\n",
      "0.117874 (0.166700) with: {'dropout_rate': 0.8}\n",
      "0.124638 (0.176264) with: {'dropout_rate': 0.9}\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.constraints import maxnorm\n",
    "\n",
    "activations = ['relu', 'tanh', 'linear']\n",
    "batch_sizes = [10, 20, 30, 40, 50, 60]\n",
    "epochs = [10, 20, 30]\n",
    "dropout_rates = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "optimisers = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, nb_epoch=10, batch_size=24, verbose=0)\n",
    "model.fit(train_x, train_y)\n",
    "# define the grid search parameters\n",
    "# just using one here for illustration, but add activation_function=activations \n",
    "# or dropout_rate=dropout_rates to grid search on other parameters\n",
    "param_grid = dict(dropout_rate = dropout_rates )\n",
    "#param_grid = dict(optimiser=optimisers, activation_function=activations, dropout_rate = dropout_rates, batch_size= batch_sizes )\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "\n",
    "print (\"Running GridSearch...\")\n",
    "grid_result = grid.fit(train_x, train_y)\n",
    "print (\"GridSearch complete\")\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've trained a model, we can use the following process to pass an audio file into our model and generate predictions, which will be the activation value (between Normal and Abnormal) at the output layer for each of the 2 possible classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features_only(filename):\n",
    "    features = np.empty((0,193))\n",
    "    X, sample_rate = librosa.load(filename)\n",
    "    stft = np.abs(librosa.stft(X))\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "    ext_features = np.hstack([mfccs,chroma,mel,contrast,tonnetz])\n",
    "    features = np.vstack([features,ext_features])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "predict_x = extract_features_only('C:/Users/apt/Desktop/Data/dataset/normal/107_1305654946865_C1.wav')\n",
    "predictions = model.predict(predict_x)\n",
    "print(np.argmax(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sound_file_paths = [\"a0001.wav\",\"a0002.wav\",\"a0003.wav\",\"a0004.wav\",\"a0005.wav\",\n",
    "                   \"a0006.wav\",\"a0007.wav\",\"a0008.wav\",\"a0009.wav\",\"a0010.wav\", \"a0011.wav\",\"a0012.wav\",\"a0013.wav\",\"a0014.wav\",\"a0015.wav\",\n",
    "                   \"a0016.wav\",\"a0017.wav\",\"a0018.wav\",\"a0019.wav\",\"a0020.wav\"]\n",
    "sound_names = [\"abnormal\",\"abnormal\",\"abnormal\",\"abnormal\",\"abnormal\",\"abnormal\",\n",
    "               \"normal\",\"abnormal\",\"normal\",\"abnormal\",\"normal\",\"normal\",\"abnormal\",\"abnormal\",\"abnormal\",\"normal\",\n",
    "               \"abnormal\",\"abnormal\",\"normal\",\"abnormal\"]\n",
    "parent_dir = 'C:/Users/apt/Desktop/Data/training/training-a/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected label ==> abnormal\n",
      "Predicted label ===> ['abnormal']\n",
      "-------------------------------\n",
      "Expected label ==> abnormal\n",
      "Predicted label ===> ['abnormal']\n",
      "-------------------------------\n",
      "Expected label ==> abnormal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\apt\\Anaconda3\\envs\\ml\\lib\\site-packages\\librosa\\core\\pitch.py:145: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  warnings.warn('Trying to estimate tuning from empty frequency set.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label ===> ['abnormal']\n",
      "-------------------------------\n",
      "Expected label ==> abnormal\n",
      "Predicted label ===> ['abnormal']\n",
      "-------------------------------\n",
      "Expected label ==> abnormal\n",
      "Predicted label ===> ['abnormal']\n",
      "-------------------------------\n",
      "Expected label ==> abnormal\n",
      "Predicted label ===> ['abnormal']\n",
      "-------------------------------\n",
      "Expected label ==> normal\n",
      "Predicted label ===> ['abnormal']\n",
      "-------------------------------\n",
      "Expected label ==> abnormal\n",
      "Predicted label ===> ['abnormal']\n",
      "-------------------------------\n",
      "Expected label ==> normal\n",
      "Predicted label ===> ['normal']\n",
      "-------------------------------\n",
      "Expected label ==> abnormal\n",
      "Predicted label ===> ['abnormal']\n",
      "-------------------------------\n",
      "Expected label ==> normal\n",
      "Predicted label ===> ['abnormal']\n",
      "-------------------------------\n",
      "Expected label ==> normal\n",
      "Predicted label ===> ['normal']\n",
      "-------------------------------\n",
      "Expected label ==> abnormal\n",
      "Predicted label ===> ['abnormal']\n",
      "-------------------------------\n",
      "Expected label ==> abnormal\n",
      "Predicted label ===> ['abnormal']\n",
      "-------------------------------\n",
      "Expected label ==> abnormal\n",
      "Predicted label ===> ['abnormal']\n",
      "-------------------------------\n",
      "Expected label ==> normal\n",
      "Predicted label ===> ['abnormal']\n",
      "-------------------------------\n",
      "Expected label ==> abnormal\n",
      "Predicted label ===> ['abnormal']\n",
      "-------------------------------\n",
      "Expected label ==> abnormal\n",
      "Predicted label ===> ['abnormal']\n",
      "-------------------------------\n",
      "Expected label ==> normal\n",
      "Predicted label ===> ['normal']\n",
      "-------------------------------\n",
      "Expected label ==> abnormal\n",
      "Predicted label ===> ['abnormal']\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "for s in range(len(sound_names)):\n",
    "\n",
    "    print (\"Expected label ==>\", sound_names[s])\n",
    "    # load audio file and extract features\n",
    "    predict_file = parent_dir + sound_file_paths[s]\n",
    "    predict_x = extract_features_only(predict_file)\n",
    "    #print(predict_x)\n",
    "    # generate prediction, passing in just a single row of features\n",
    "    predictions = model.predict(predict_x)\n",
    "    #for i in range(len(predictions[0])):\n",
    "    #    print sound_names[i], \"=\", round(predictions[0,i] * 100, 1)\n",
    "    \n",
    "    # get the indices of the top 2 predictions, invert into descending order\n",
    "    #If youre not familiar, the np.partition does a partial sort on the vector,\n",
    "    #just separating the numbers into two groups (partitions) one of size k, and the other len-k \n",
    "    #such that all the values in the first group are less than all the values in the second.\n",
    "    #Thats np.partition, while np.argpartition does the same thing but gives you the indices\n",
    "    #into the vector rather than the values.\n",
    "    ind = np.argpartition(predictions[0], -2)\n",
    "    \n",
    "    inverted = label_encoder.inverse_transform([argmax(ind)])\n",
    "    print (\"Predicted label ===>\", inverted)\n",
    "    print(\"-------------------------------\")\n",
    "    ind[np.argsort(predictions[0][ind])]\n",
    "    ind = ind[::-1]\n",
    "    #print(ind[0])\n",
    "    #print(ind[1])\n",
    "    \n",
    "    \n",
    "    #print (\"Top guess: \", sound_names[ind[0]], \" (\",round(predictions[0,ind[0]],3),\")\")\n",
    "    #print (\"2nd guess: \", sound_names[ind[1]], \" (\",round(predictions[0,ind[1]],3),\")\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
